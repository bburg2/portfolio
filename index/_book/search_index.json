[["introduction.html", "1 Introduction", " 1 Introduction 1.0.1 Introductie In ons project gaan we in op de erasmusladder, dit is een apparaat wat een muis over een aantal sensoren laat lopen. De ladder slaat het elke keer op als een muis over en sensor loopt. Hierdoor kan er gemeten worden wanneer een muis moeite heeft met lopen. Dit komt vaak door een fout in het cerrebelum. 1.0.2 Bibliography @cupidoDetectingCerebellarPhenotypes; @sathyanesanCerebellarContributionLocomotor2019; @vandervaartMotorDeficitsNeurofibromatosis2011; @vinuezavelozCerebellarControlGait2015 "],["example-data-analysis.html", "2 Example Data Analysis", " 2 Example Data Analysis ###Assignment 1.1 #install.packages(readxl) #install.packages(tidyverse) library(readxl) library(tidyverse) library(here) RawData: dbl compName: chr compConcentration: chr compConcentration is niet goed geimporteerd en zou een dbl moeten zijn. #compConcentration in numeric veranderen data$compConcentration &lt;- as.numeric(data$compConcentration) ## Warning: NAs introduced by coercion #grafiek maken ggplot(data = data, aes(x = compConcentration, y = RawData)) + geom_point(aes(color = compName, shape = compName))+ labs(title = &quot;Number of offspring per concentration&quot;, y = &quot;Number of offspring&quot;, x = &quot;Concentration of compound&quot;) + theme_minimal() ## Warning: Removed 6 rows containing missing values (geom_point). E: in de plot is compConcentration al naar een nummer veranderd. als dit niet zou gebeuren zou de x-as onleesbaar worden, ook wordt het dan moeilijk te zien wat de concentratie is. #compConcentration in numeric veranderen data$compConcentration &lt;- as.numeric(data$compConcentration) #grafiek maken ggplot(data = data, aes(x = log10(compConcentration), y = RawData)) + geom_point(aes(color = compName, shape = compName, position = &quot;jitter&quot;))+ labs(title = &quot;Number of offspring per concentration&quot;, y = &quot;Number of offspring&quot;, x = &quot;log10 Concentration of compound&quot;) + theme_minimal() ## Warning: Ignoring unknown aesthetics: position ## Warning: Removed 6 rows containing missing values (geom_point). Nog niet hellemaal duidelijk hoe jitter werkt. The positive control for this experiments is Ethanol. (H) The negative control for this experiment is S-medium. I: Eerst testen of de data normaal verdeeld is per stof doormiddel van een shapiro-wilk. Vervolgens een levene-test uitvoeren om te testen voor variatie. Hierna kan een T-test uitgevoerd worden ten over de positieve controle (ethanol) met elke stof. #data filteren op de negatieve controle data_negative &lt;- data %&gt;% filter(data$expType == &quot;controlNegative&quot;) #De gemiddelde berekenen van het rawdata colom van de negative controle mean_negative &lt;- mean(data_negative$RawData, na.rm = TRUE) #De data normaliseren op basis van het gemiddelde van de negatieve controle data$RawData &lt;- data$RawData - mean_negative #grafiek maken ggplot(data = data, aes(x = log10(compConcentration), y = RawData)) + geom_point(aes(color = compName, shape = compName, position = &quot;jitter&quot;))+ labs(title = &quot;Number of offspring per concentration Normalised&quot;, y = &quot;Number of offspring&quot;, x = &quot;log10 Concentration of compound&quot;) + theme_minimal() ## Warning: Ignoring unknown aesthetics: position ## Warning: Removed 6 rows containing missing values (geom_point). Ik vermoed dat ik of een foute negatieve controle heb gebruikt of dat ik de data four heb genormaliseerd K: Nu is de data van de negative controle er afgehaald, wat altijd de bedoeling want de negatieve controle zou geen effect moeten hebben "],["reproducibility.html", "3 reproducibility 3.1 Part 1 3.2 Part 2", " 3 reproducibility 3.1 Part 1 3.1.1 Link naar artikel https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7583697/ 3.1.2 References Edward E. Walsh, M.D., Robert W. Frenck, Jr., M.D., Ann R. Falsey, M.D., Nicholas Kitchin, M.D., Judith Absalon, M.D.,corresponding author Alejandra Gurtman, M.D., Stephen Lockhart, D.M., Kathleen Neuzil, M.D., Mark J. Mulligan, M.D., Ruth Bailey, B.Sc., Kena A. Swanson, Ph.D., Ping Li, Ph.D., Kenneth Koury, Ph.D., Warren Kalina, Ph.D., David Cooper, Ph.D., Camila Fontes-Garfias, B.Sc., Pei-Yong Shi, Ph.D., Özlem Türeci, M.D., Kristin R. Tompkins, B.Sc., Kirsten E. Lyke, M.D., Vanessa Raabe, M.D., Philip R. Dormitzer, M.D., Kathrin U. Jansen, Ph.D., Uğur Şahin, M.D., and William C. Gruber, M.D. 3.1.3 Criteria artikel Transparency Criteria Definition Response Type Response type Article Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. Binary Yes Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. Binary Yes Data Location Where the article’s data can be accessed, either raw or processed. Found Value Op aanvraag Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. Binary; Found Value No Author Review The professionalism of the contact information that the author has provided in the manuscript. Found Value Te vinden bij Author information Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. Binary Yes Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. Binary Yes Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. Binary No 3.1.4 Overige data Het protocol, de ethics en de data sharing statement zijn onder aan het artikel te vinden. 3.1.5 Extra’s over artikel over het algenmeen is het een goed artikel, die de werking van twee verschillende vaccins voor covid-19 test. De meeste criteria zijn goed. Het experiment maakt gebruik van een placebotrail waar een deel van de mensen een nep vaccin krijgen en een deel van de mensen een echt vaccin. 3.2 Part 2 Link naar artikel https://osf.io/wqc25/ 3.2.1 J: Eerst maken ze een aantal nieuwe functies aan die ze verderop gaan gebruiken. Vervolgens laden ze de samplegroepen van het experiment in, ze controleren ook of er missing values zijn. ze maken een barplot van deze samples. Vervolgens gaan ze verschillende grafiek etc van deze data maken 3.2.2 K: 3, de code is aanwezig met comments, maar de comments zijn niet altijd even duidelijk. 3.2.3 Opdracht L, M en N library(here) # read data --------------------------------------------------------------- # sample 1 sample1 &lt;- read.csv(here(&quot;data&quot;,&quot;sample1_use for revision 1.csv&quot;)) sample1 &lt;- sample1[sample1$include_1,] # sample 2 sample2 &lt;- read.csv(here(&quot;data&quot;,&quot;sample2_use for revision 1.csv&quot;)) sample2 &lt;- sample2[sample2$include_1,] # combine samples for the additional analyses data &lt;- rbind(sample1, sample2) # packages ---------------------------------------------------------------- # functie inladen gg_color_hue &lt;- function(n) { hues = seq(15, 375, length = n + 1) hcl(h = hues, l = 65, c = 100)[1:n] } get_max_daily &lt;- function(x){ x &lt;- x + c(1:4, 9:12, 17:20, 25:27) x &lt;- x[x &lt; ymd(&quot;2020-04-13 UTC&quot;)] return(x) } # install.packages(&quot;lubridate&quot;) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union # ------------------------------------------------------------------------- ## define colors c &lt;- gg_color_hue(2) col.s1 &lt;- c[1] col.s2 &lt;- c[2] # completed baseline surveys per day that are included in the study data_l2_s1 &lt;- unique(sample1[c(&quot;ID&quot;, &quot;b_baseline_ended&quot;)]) data_l2_s2 &lt;- unique(sample2[c(&quot;ID&quot;, &quot;b_baseline_ended&quot;)]) # no missings on this variable any(is.na(data_l2_s1[2])) ## [1] FALSE any(is.na(data_l2_s2[2])) ## [1] FALSE date_s1 &lt;- ymd_hms(data_l2_s1$b_baseline_ended) hour(date_s1) &lt;- 0 minute(date_s1) &lt;- 0 second(date_s1) &lt;- 0 date_s2 &lt;- ymd_hms(data_l2_s2$b_baseline_ended) hour(date_s2) &lt;- 0 minute(date_s2) &lt;- 0 second(date_s2) &lt;- 0 # number of baseline surveys completed t_date_baseline_1 &lt;- table(ymd(date_s1)) t_date_baseline_2 &lt;- table(ymd(date_s2)) t_date_baseline_1 &lt;- c(t_date_baseline_1, &quot;2020-04-12&quot; = 0) t_date_baseline_12 &lt;- rbind(t_date_baseline_1, t_date_baseline_2) # barplot sample 1 and 2 baseline participation --------------------------- layout(matrix(1:2, 1, 2, byrow = TRUE)) b &lt;- barplot(t_date_baseline_12, beside = TRUE, ylim = c(0, 800), names.arg = rep(&quot;&quot;, length(t_date_baseline_12)), col = c(col.s1, col.s2), axes = FALSE) box() axis(2, las = 2, cex.axis = 0.8) s &lt;- seq(1, 28, 7) labels &lt;- colnames(t_date_baseline_12)[s] axis(1, at = ((b[1,] + b[2,])/2)[s], labels = labels, cex.axis = 0.8) text(&quot;A&quot;, x = ((b[1,] + b[2,])/2)[2], y = 800*.9, cex = 4, col = &quot;grey&quot;) legend(x = ((b[1,] + b[2,])/2)[15], y = 800, legend = c(&quot;Sample 1&quot;, &quot;Sample 2&quot;), fill = c(col.s1, col.s2), bty = &quot;n&quot;) # dates at which a daily survey could have been completed: max_daily_dates_s1 &lt;- lapply(ymd(date_s1), get_max_daily) max_daily_dates_s2 &lt;- lapply(ymd(date_s2), get_max_daily) max_dates_s1 &lt;- do.call(&quot;c&quot;, max_daily_dates_s1) max_dates_s2 &lt;- do.call(&quot;c&quot;, max_daily_dates_s2) obtained_dates_s1 &lt;- sample1$daily_date obtained_dates_s2 &lt;- sample2$daily_date t_max_dates_s1 &lt;- table(max_dates_s1) t_max_dates_s2 &lt;- table(max_dates_s2) t_obtained_dates_s1 &lt;- table(obtained_dates_s1) t_obtained_dates_s2 &lt;- table(obtained_dates_s2) t_obtained_dates_s12 &lt;- rbind(t_obtained_dates_s1, t_obtained_dates_s2) b &lt;- barplot(t_obtained_dates_s12, beside = TRUE, ylim = c(0, 2000), names.arg = rep(&quot;&quot;, length(t_obtained_dates_s12)), col = c(col.s1, col.s2), axes = FALSE) box() axis(2, las = 2, cex.axis = 0.8) labels &lt;- colnames(t_obtained_dates_s12)[s] axis(1, at = ((b[1,] + b[2,])/2)[s], labels = labels, cex.axis = 0.8) lines(y = t_max_dates_s1, x = b[1,], type = &quot;p&quot;, pch = &quot;-&quot;, col = col.s1, cex = 1.5) lines(y = t_max_dates_s2, x = b[2,], type = &quot;p&quot;, pch = &quot;-&quot;, col = col.s2, cex = 1.5) text(&quot;B&quot;, x = ((b[1,] + b[2,])/2)[2], y = 2000*.9, cex = 4, col = &quot;grey&quot;) legend(x = ((b[1,] + b[2,])/2)[15], y = 2000, legend = c(&quot;Sample 1&quot;, &quot;Sample 2&quot;), fill = c(col.s1, col.s2), bty = &quot;n&quot;) # difference obtained and maximum ----------------------------------------- obtained_total &lt;- sum(t_obtained_dates_s12) max_reports_total &lt;- sum(c(t_max_dates_s1, t_max_dates_s2)) round(obtained_total/max_reports_total*100, 2) ## [1] 75.74 # average surveys per day ------------------------------------------------- median(colSums(t_obtained_dates_s12)) ## [1] 1468 # average number of loneliness scores per participant --------------------- s1_lst &lt;- split(sample1, f = sample1$ID) n_1 &lt;- unlist(lapply(s1_lst, function(x) sum(!is.na(x$loneliness)))) mean(n_1) ## [1] 8.150741 sd(n_1) ## [1] 3.359446 range(n_1) ## [1] 0 15 s2_lst &lt;- split(sample2, f = sample2$ID) n_2 &lt;- unlist(lapply(s2_lst, function(x) sum(!is.na(x$loneliness)))) mean(n_2) ## [1] 8.124586 sd(n_2) ## [1] 3.399153 range(n_2) ## [1] 0 15 # distribution of participants across number of daily surveys layout(1) b &lt;- barplot(table(c(n_1, n_2)), main = &quot;&quot;, ylab = &quot;valid loneliness scores&quot;, xlab = &quot;number of completed daily surveys&quot;, ylim = c(0, 900), lwd = 1.3) box(lwd = 1.3) # surveys, not valid measures n_1 &lt;- unlist(lapply(s1_lst, function(x) nrow(x))) n_2 &lt;- unlist(lapply(s2_lst, function(x) nrow(x))) mean(n_1) ## [1] 8.269769 sd(n_1) ## [1] 3.318693 range(n_1) ## [1] 1 15 mean(n_2) ## [1] 8.25207 sd(n_2) ## [1] 3.359575 range(n_2) ## [1] 1 15 b &lt;- barplot(table(c(n_1, n_2)), main = &quot;&quot;, ylab = &quot;N&quot;, xlab = &quot;number of completed daily surveys&quot;, ylim = c(0, 1000), lwd = 1.3) box(lwd = 1.3) # N and measurement occasions --------------------------------------------- sample1_lst &lt;- split(sample1, f = sample1$ID) sample2_lst &lt;- split(sample2, f = sample2$ID) length(sample1_lst) ## [1] 2428 length(sample2_lst) ## [1] 2416 length(sample1_lst) + length(sample2_lst) ## [1] 4844 nrow(sample1) ## [1] 20079 nrow(sample2) ## [1] 19937 nrow(sample1) + nrow(sample2) ## [1] 40016 # demographic variables --------------------------------------------------- names &lt;- names(sample1) variables_level_2 &lt;- grep(x = names, pattern = &quot;ID|group|b_|var_|federal&quot;, value = TRUE) data_l2_s1 &lt;- unique(sample1[variables_level_2]) data_l2_s2 &lt;- unique(sample2[variables_level_2]) ## age mean(data_l2_s1$b_demo_age_1) ## [1] 37.29462 sd(data_l2_s1$b_demo_age_1) ## [1] 14.32523 mean(data_l2_s2$b_demo_age_1) ## [1] 37.57201 sd(data_l2_s2$b_demo_age_1) ## [1] 14.24426 # generate level 2 data frame for all participants data_l2 &lt;- unique(data[c(grep(x = names(data), pattern = &quot;ID|b_demo|b_work|b_corona&quot;, value = TRUE))]) mean(data_l2$b_demo_age_1) ## [1] 37.87923 sd(data_l2$b_demo_age_1) ## [1] 14.40773 barplot(table(data_l2$b_demo_age_1), main = &quot;Distribution of age across the total sample&quot;, lwd = 1.3, ylim = c(0, 200)) box(lwd = 1.3) ## quartiles of age quantile(data_l2$b_demo_age_1) ## 0% 25% 50% 75% 100% ## 18 27 34 48 88 3.2.4 N: de path was eerst fout die naar de data leide die heb ik goed gezet. Ook werden de functies ingeladen in een andere file. De functie die ontbreekte (gg_color_hue en get_max_daily), heb ik aan de code toegevoegd en toen werkte die wel. 3.2.5 O: 4, Er moesten maar een paar dingen veranderd worden om de figuren te krijgen. 3.2.6 P: 4, Voor reproducibility, het was redelijk gemakkelijk om de figuren te genereren "],["resume-bas-van-der-burg.html", "4 Resume: Bas van der Burg 4.1 Opleiding 4.2 Ervaring 4.3 Overig", " 4 Resume: Bas van der Burg Cambridgelaan 805 bvdb1@hotmail.com 3584 DW Utrecht Nederland 06-28304767 4.1 Opleiding 2022-2022 (Verwacht) Minor: Data Science; Hogeschool Utrecht Ervaring in: R, Bash, Python, SQL en ShinyApp 2018-2022 Life Science; Hogeschool Utrecht Specialisatie: Biomolecular Research 4.2 Ervaring Labtechnieken: De labtechnieken die ik in de afgelopen jaren heb toegepast: Gel-electroforese Long Read DNA sequencing met behulp van de minION PCR 4.3 Overig Talen: Nederlands Engels "],["future-plans.html", "5 Future plans", " 5 Future plans 5.0.1 Wat wil ik? Ik zou later graag iets met next-generation sequencingen willen doen. Het lijkt me dan leuk om een deel in het lab te staan maar ook een deel de data te verwerken. 5.0.2 wat heb ik hiervoor nodig? IK ben gaan zoeken naar vacatures die iets te maken hebben met NGS. Vaak zie ik Python langs komen, dus ik wel me mischien verdiepen in Python maar ik weet het nog niet zeker. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

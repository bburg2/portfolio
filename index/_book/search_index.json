[["project-introduction.html", "1 Project Introduction", " 1 Project Introduction 1.0.1 Introductie To learn programming better my school assigned me to a project. Here I will give a short introduction to the project. 1.0.2 about the project The project is about the erasmusladder, this is a device made for testing motor function of mice. The device does this by having sensors in every step the mice can possibly take. After the mouse walks across one of these erasmusladders data is provided by the erasmusladder. This data set cointains 120 variables, these variables are about every step a mouse can take, for example there are nine different high to low variables, these are the steps the programs sees as a misstep. The erasmusladder is usefull for testing mice under different conditions. For example one study looked at the difference between wilt-type mice and mice with degenerating purkinje cells [@vinuezavelozCerebellarControlGait2015 ]. The erasmusladder also contains two different air outlets to control the moment of departure and the speed of the mice[@vandervaartMotorDeficitsNeurofibromatosis2011] 1.0.3 Bibliography @cupidoDetectingCerebellarPhenotypes; @sathyanesanCerebellarContributionLocomotor2019; @vandervaartMotorDeficitsNeurofibromatosis2011; @vinuezavelozCerebellarControlGait2015 "],["example-data-analysis.html", "2 Example Data Analysis", " 2 Example Data Analysis ###Assignment 1.1 #install.packages(readxl) #install.packages(tidyverse) library(readxl) library(tidyverse) library(here) RawData: dbl compName: chr compConcentration: chr compConcentration is niet goed geimporteerd en zou een dbl moeten zijn. #compConcentration in numeric veranderen data$compConcentration &lt;- as.numeric(data$compConcentration) ## Warning: NAs introduced by coercion #grafiek maken ggplot(data = data, aes(x = compConcentration, y = RawData)) + geom_point(aes(color = compName, shape = compName))+ labs(title = &quot;Number of offspring per concentration&quot;, y = &quot;Number of offspring&quot;, x = &quot;Concentration of compound&quot;) + theme_minimal() ## Warning: Removed 6 rows containing missing values (geom_point). E: in de plot is compConcentration al naar een nummer veranderd. als dit niet zou gebeuren zou de x-as onleesbaar worden, ook wordt het dan moeilijk te zien wat de concentratie is. #compConcentration in numeric veranderen data$compConcentration &lt;- as.numeric(data$compConcentration) #grafiek maken ggplot(data = data, aes(x = log10(compConcentration), y = RawData)) + geom_point(aes(color = compName, shape = compName, position = &quot;jitter&quot;))+ labs(title = &quot;Number of offspring per concentration&quot;, y = &quot;Number of offspring&quot;, x = &quot;log10 Concentration of compound&quot;) + theme_minimal() ## Warning: Ignoring unknown aesthetics: position ## Warning: Removed 6 rows containing missing values (geom_point). Nog niet hellemaal duidelijk hoe jitter werkt. The positive control for this experiments is Ethanol. (H) The negative control for this experiment is S-medium. I: Eerst testen of de data normaal verdeeld is per stof doormiddel van een shapiro-wilk. Vervolgens een levene-test uitvoeren om te testen voor variatie. Hierna kan een T-test uitgevoerd worden ten over de positieve controle (ethanol) met elke stof. #data filteren op de negatieve controle data_negative &lt;- data %&gt;% filter(data$expType == &quot;controlNegative&quot;) #De gemiddelde berekenen van het rawdata colom van de negative controle mean_negative &lt;- mean(data_negative$RawData, na.rm = TRUE) #De data normaliseren op basis van het gemiddelde van de negatieve controle data$RawData &lt;- data$RawData - mean_negative #grafiek maken ggplot(data = data, aes(x = log10(compConcentration), y = RawData)) + geom_point(aes(color = compName, shape = compName, position = &quot;jitter&quot;))+ labs(title = &quot;Number of offspring per concentration Normalised&quot;, y = &quot;Number of offspring&quot;, x = &quot;log10 Concentration of compound&quot;) + theme_minimal() ## Warning: Ignoring unknown aesthetics: position ## Warning: Removed 6 rows containing missing values (geom_point). Ik vermoed dat ik of een foute negatieve controle heb gebruikt of dat ik de data four heb genormaliseerd K: Nu is de data van de negative controle er afgehaald, wat altijd de bedoeling want de negatieve controle zou geen effect moeten hebben "],["reproducibility.html", "3 reproducibility 3.1 Part 1 3.2 Part 2", " 3 reproducibility 3.1 Part 1 3.1.1 Link naar artikel https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7583697/ 3.1.2 References Edward E. Walsh, M.D., Robert W. Frenck, Jr., M.D., Ann R. Falsey, M.D., Nicholas Kitchin, M.D., Judith Absalon, M.D.,corresponding author Alejandra Gurtman, M.D., Stephen Lockhart, D.M., Kathleen Neuzil, M.D., Mark J. Mulligan, M.D., Ruth Bailey, B.Sc., Kena A. Swanson, Ph.D., Ping Li, Ph.D., Kenneth Koury, Ph.D., Warren Kalina, Ph.D., David Cooper, Ph.D., Camila Fontes-Garfias, B.Sc., Pei-Yong Shi, Ph.D., Özlem Türeci, M.D., Kristin R. Tompkins, B.Sc., Kirsten E. Lyke, M.D., Vanessa Raabe, M.D., Philip R. Dormitzer, M.D., Kathrin U. Jansen, Ph.D., Uğur Şahin, M.D., and William C. Gruber, M.D. 3.1.3 Criteria artikel Transparency Criteria Definition Response Type Response type Article Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. Binary Yes Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. Binary Yes Data Location Where the article’s data can be accessed, either raw or processed. Found Value Op aanvraag Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. Binary; Found Value No Author Review The professionalism of the contact information that the author has provided in the manuscript. Found Value Te vinden bij Author information Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. Binary Yes Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. Binary Yes Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. Binary No 3.1.4 Overige data Het protocol, de ethics en de data sharing statement zijn onder aan het artikel te vinden. 3.1.5 Extra’s over artikel over het algenmeen is het een goed artikel, die de werking van twee verschillende vaccins voor covid-19 test. De meeste criteria zijn goed. Het experiment maakt gebruik van een placebotrail waar een deel van de mensen een nep vaccin krijgen en een deel van de mensen een echt vaccin. 3.2 Part 2 Link naar artikel https://osf.io/wqc25/ 3.2.1 J: Eerst maken ze een aantal nieuwe functies aan die ze verderop gaan gebruiken. Vervolgens laden ze de samplegroepen van het experiment in, ze controleren ook of er missing values zijn. ze maken een barplot van deze samples. Vervolgens gaan ze verschillende grafiek etc van deze data maken 3.2.2 K: 3, de code is aanwezig met comments, maar de comments zijn niet altijd even duidelijk. 3.2.3 Opdracht L, M en N library(here) # read data --------------------------------------------------------------- # sample 1 sample1 &lt;- read.csv(here(&quot;data&quot;,&quot;sample1_use for revision 1.csv&quot;)) sample1 &lt;- sample1[sample1$include_1,] # sample 2 sample2 &lt;- read.csv(here(&quot;data&quot;,&quot;sample2_use for revision 1.csv&quot;)) sample2 &lt;- sample2[sample2$include_1,] # combine samples for the additional analyses data &lt;- rbind(sample1, sample2) # packages ---------------------------------------------------------------- # functie inladen gg_color_hue &lt;- function(n) { hues = seq(15, 375, length = n + 1) hcl(h = hues, l = 65, c = 100)[1:n] } get_max_daily &lt;- function(x){ x &lt;- x + c(1:4, 9:12, 17:20, 25:27) x &lt;- x[x &lt; ymd(&quot;2020-04-13 UTC&quot;)] return(x) } # install.packages(&quot;lubridate&quot;) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union # ------------------------------------------------------------------------- ## define colors c &lt;- gg_color_hue(2) col.s1 &lt;- c[1] col.s2 &lt;- c[2] # completed baseline surveys per day that are included in the study data_l2_s1 &lt;- unique(sample1[c(&quot;ID&quot;, &quot;b_baseline_ended&quot;)]) data_l2_s2 &lt;- unique(sample2[c(&quot;ID&quot;, &quot;b_baseline_ended&quot;)]) # no missings on this variable any(is.na(data_l2_s1[2])) ## [1] FALSE any(is.na(data_l2_s2[2])) ## [1] FALSE date_s1 &lt;- ymd_hms(data_l2_s1$b_baseline_ended) hour(date_s1) &lt;- 0 minute(date_s1) &lt;- 0 second(date_s1) &lt;- 0 date_s2 &lt;- ymd_hms(data_l2_s2$b_baseline_ended) hour(date_s2) &lt;- 0 minute(date_s2) &lt;- 0 second(date_s2) &lt;- 0 # number of baseline surveys completed t_date_baseline_1 &lt;- table(ymd(date_s1)) t_date_baseline_2 &lt;- table(ymd(date_s2)) t_date_baseline_1 &lt;- c(t_date_baseline_1, &quot;2020-04-12&quot; = 0) t_date_baseline_12 &lt;- rbind(t_date_baseline_1, t_date_baseline_2) # barplot sample 1 and 2 baseline participation --------------------------- layout(matrix(1:2, 1, 2, byrow = TRUE)) b &lt;- barplot(t_date_baseline_12, beside = TRUE, ylim = c(0, 800), names.arg = rep(&quot;&quot;, length(t_date_baseline_12)), col = c(col.s1, col.s2), axes = FALSE) box() axis(2, las = 2, cex.axis = 0.8) s &lt;- seq(1, 28, 7) labels &lt;- colnames(t_date_baseline_12)[s] axis(1, at = ((b[1,] + b[2,])/2)[s], labels = labels, cex.axis = 0.8) text(&quot;A&quot;, x = ((b[1,] + b[2,])/2)[2], y = 800*.9, cex = 4, col = &quot;grey&quot;) legend(x = ((b[1,] + b[2,])/2)[15], y = 800, legend = c(&quot;Sample 1&quot;, &quot;Sample 2&quot;), fill = c(col.s1, col.s2), bty = &quot;n&quot;) # dates at which a daily survey could have been completed: max_daily_dates_s1 &lt;- lapply(ymd(date_s1), get_max_daily) max_daily_dates_s2 &lt;- lapply(ymd(date_s2), get_max_daily) max_dates_s1 &lt;- do.call(&quot;c&quot;, max_daily_dates_s1) max_dates_s2 &lt;- do.call(&quot;c&quot;, max_daily_dates_s2) obtained_dates_s1 &lt;- sample1$daily_date obtained_dates_s2 &lt;- sample2$daily_date t_max_dates_s1 &lt;- table(max_dates_s1) t_max_dates_s2 &lt;- table(max_dates_s2) t_obtained_dates_s1 &lt;- table(obtained_dates_s1) t_obtained_dates_s2 &lt;- table(obtained_dates_s2) t_obtained_dates_s12 &lt;- rbind(t_obtained_dates_s1, t_obtained_dates_s2) b &lt;- barplot(t_obtained_dates_s12, beside = TRUE, ylim = c(0, 2000), names.arg = rep(&quot;&quot;, length(t_obtained_dates_s12)), col = c(col.s1, col.s2), axes = FALSE) box() axis(2, las = 2, cex.axis = 0.8) labels &lt;- colnames(t_obtained_dates_s12)[s] axis(1, at = ((b[1,] + b[2,])/2)[s], labels = labels, cex.axis = 0.8) lines(y = t_max_dates_s1, x = b[1,], type = &quot;p&quot;, pch = &quot;-&quot;, col = col.s1, cex = 1.5) lines(y = t_max_dates_s2, x = b[2,], type = &quot;p&quot;, pch = &quot;-&quot;, col = col.s2, cex = 1.5) text(&quot;B&quot;, x = ((b[1,] + b[2,])/2)[2], y = 2000*.9, cex = 4, col = &quot;grey&quot;) legend(x = ((b[1,] + b[2,])/2)[15], y = 2000, legend = c(&quot;Sample 1&quot;, &quot;Sample 2&quot;), fill = c(col.s1, col.s2), bty = &quot;n&quot;) # difference obtained and maximum ----------------------------------------- obtained_total &lt;- sum(t_obtained_dates_s12) max_reports_total &lt;- sum(c(t_max_dates_s1, t_max_dates_s2)) round(obtained_total/max_reports_total*100, 2) ## [1] 75.74 # average surveys per day ------------------------------------------------- median(colSums(t_obtained_dates_s12)) ## [1] 1468 # average number of loneliness scores per participant --------------------- s1_lst &lt;- split(sample1, f = sample1$ID) n_1 &lt;- unlist(lapply(s1_lst, function(x) sum(!is.na(x$loneliness)))) mean(n_1) ## [1] 8.150741 sd(n_1) ## [1] 3.359446 range(n_1) ## [1] 0 15 s2_lst &lt;- split(sample2, f = sample2$ID) n_2 &lt;- unlist(lapply(s2_lst, function(x) sum(!is.na(x$loneliness)))) mean(n_2) ## [1] 8.124586 sd(n_2) ## [1] 3.399153 range(n_2) ## [1] 0 15 # distribution of participants across number of daily surveys layout(1) b &lt;- barplot(table(c(n_1, n_2)), main = &quot;&quot;, ylab = &quot;valid loneliness scores&quot;, xlab = &quot;number of completed daily surveys&quot;, ylim = c(0, 900), lwd = 1.3) box(lwd = 1.3) # surveys, not valid measures n_1 &lt;- unlist(lapply(s1_lst, function(x) nrow(x))) n_2 &lt;- unlist(lapply(s2_lst, function(x) nrow(x))) mean(n_1) ## [1] 8.269769 sd(n_1) ## [1] 3.318693 range(n_1) ## [1] 1 15 mean(n_2) ## [1] 8.25207 sd(n_2) ## [1] 3.359575 range(n_2) ## [1] 1 15 b &lt;- barplot(table(c(n_1, n_2)), main = &quot;&quot;, ylab = &quot;N&quot;, xlab = &quot;number of completed daily surveys&quot;, ylim = c(0, 1000), lwd = 1.3) box(lwd = 1.3) # N and measurement occasions --------------------------------------------- sample1_lst &lt;- split(sample1, f = sample1$ID) sample2_lst &lt;- split(sample2, f = sample2$ID) length(sample1_lst) ## [1] 2428 length(sample2_lst) ## [1] 2416 length(sample1_lst) + length(sample2_lst) ## [1] 4844 nrow(sample1) ## [1] 20079 nrow(sample2) ## [1] 19937 nrow(sample1) + nrow(sample2) ## [1] 40016 # demographic variables --------------------------------------------------- names &lt;- names(sample1) variables_level_2 &lt;- grep(x = names, pattern = &quot;ID|group|b_|var_|federal&quot;, value = TRUE) data_l2_s1 &lt;- unique(sample1[variables_level_2]) data_l2_s2 &lt;- unique(sample2[variables_level_2]) ## age mean(data_l2_s1$b_demo_age_1) ## [1] 37.29462 sd(data_l2_s1$b_demo_age_1) ## [1] 14.32523 mean(data_l2_s2$b_demo_age_1) ## [1] 37.57201 sd(data_l2_s2$b_demo_age_1) ## [1] 14.24426 # generate level 2 data frame for all participants data_l2 &lt;- unique(data[c(grep(x = names(data), pattern = &quot;ID|b_demo|b_work|b_corona&quot;, value = TRUE))]) mean(data_l2$b_demo_age_1) ## [1] 37.87923 sd(data_l2$b_demo_age_1) ## [1] 14.40773 barplot(table(data_l2$b_demo_age_1), main = &quot;Distribution of age across the total sample&quot;, lwd = 1.3, ylim = c(0, 200)) box(lwd = 1.3) ## quartiles of age quantile(data_l2$b_demo_age_1) ## 0% 25% 50% 75% 100% ## 18 27 34 48 88 3.2.4 N: de path was eerst fout die naar de data leide die heb ik goed gezet. Ook werden de functies ingeladen in een andere file. De functie die ontbreekte (gg_color_hue en get_max_daily), heb ik aan de code toegevoegd en toen werkte die wel. 3.2.5 O: 4, Er moesten maar een paar dingen veranderd worden om de figuren te krijgen. 3.2.6 P: 4, Voor reproducibility, het was redelijk gemakkelijk om de figuren te genereren "],["resume.html", "4 resume", " 4 resume "],["resume-bas-van-der-burg.html", "5 Resume: Bas van der Burg 5.1 Opleiding 5.2 Ervaring 5.3 Overig", " 5 Resume: Bas van der Burg Cambridgelaan 805 bvdb1@hotmail.com 3584 DW Utrecht Nederland 06-28304767 5.1 Opleiding 2022-2022 (Verwacht) Minor: Data Science; Hogeschool Utrecht Ervaring in: R, Bash, Python, SQL en ShinyApp 2018-2022 Life Science; Hogeschool Utrecht Specialisatie: Biomolecular Research 5.2 Ervaring Labtechnieken: De labtechnieken die ik in de afgelopen jaren heb toegepast: Gel-electroforese Long Read DNA sequencing met behulp van de minION PCR 5.3 Overig Talen: Nederlands Engels "],["future-plans.html", "6 Future plans", " 6 Future plans 6.0.1 Wat wil ik? Ik zou later graag iets met next-generation sequencingen willen doen. Het lijkt me dan leuk om een deel in het lab te staan maar ook een deel de data te verwerken. 6.0.2 wat heb ik hiervoor nodig? IK ben gaan zoeken naar vacatures die iets te maken hebben met NGS. Vaak zie ik Python langs komen, dus ik wel me mischien verdiepen in Python maar ik weet het nog niet zeker. "],["sql-data-analysis.html", "7 SQL data analysis", " 7 SQL data analysis In this report I add three different datasets to an sql database and join the table together. With this data I make three different graphs to show my skill in R and SQL. First thing is loading all the packages I use library(dslabs) library(readr) library(tidyverse) library(here) library(DBI) library(plotly) Here I load the data with the use of the “read_csv” command and the “here package” # Laden van flu data en de eerste 10 rows skippen flu_data &lt;- read_csv(here(&quot;data&quot;,&quot;flu_data.csv&quot;), skip = 10) # Laden van denque data en de eerste 10 rows skippen dengue_data &lt;- read_csv(here(&quot;data&quot;,&quot;dengue_data.csv&quot;), skip = 10) # Laden van gampinder in gampinder (niet nuttig). gapminder &lt;- gapminder Here a make the tables tidy, this for later use (is easier to work with tidy data). # gapminder zelfde colnaam geven gapminder_tidy &lt;- gapminder %&gt;% rename(Date = year) # flu_data tidy maken flu_data_tidy &lt;- pivot_longer(data = flu_data, cols = -c(&quot;Date&quot;), names_to = &quot;country&quot;, values_to = &quot;cases&quot;) # en factor van country maken flu_data_tidy$country &lt;- as.factor(flu_data_tidy$country) # dengue_data tidy maken dengue_data_tidy &lt;- pivot_longer(data = dengue_data, cols = -c(&quot;Date&quot;), names_to = &quot;country&quot;, values_to = &quot;activity&quot;) # en factor van country maken dengue_data_tidy$country &lt;- as.factor(dengue_data_tidy$country) After this I exported the tidy data to csv an rds files # Oplsaan als CSV bestand write_csv(flu_data_tidy, path = here(&quot;data&quot;,&quot;flu_data_tidy.csv&quot;)) # Oplsaan als CSV bestand write_csv(dengue_data_tidy, path = here(&quot;data&quot;,&quot;dengue_data_tidy.csv&quot;)) # Oplsaan als CSV bestand write_csv(gapminder_tidy, path = here(&quot;data&quot;,&quot;gapminder_tidy.csv&quot;)) # opslaan als rds bestand write_rds(flu_data_tidy, path = here(&quot;data&quot;,&quot;flu_data_tidy.rds&quot;)) # opslaan als rds bestand write_rds(dengue_data_tidy, path = here(&quot;data&quot;,&quot;dengue_data_tidy.rds&quot;)) # opslaan als rds bestand write_rds(gapminder_tidy, path = here(&quot;data&quot;,&quot;gapminder_tidy.rds&quot;)) These are the commands I used in the sql database with the program DBeaver # en table maken CREATE TABLE flu_data ( Date VARCHAR(50), country VARCHAR(50), cases VARCHAR(50), CONSTRAINT PK_flu PRIMARY KEY (Date,country) ); # de date naar de table verplaatsen COPY flu_data FROM &#39;C:/Users/Bas/Desktop/School/Programmeren/datascience/portfolio/data/flu_data_tidy.csv&#39; WITH (FORMAT csv); # de table laten zien SELECT * FROM flu_data; # en table maken CREATE TABLE dengue_data ( Date VARCHAR(50), country VARCHAR(50), activity VARCHAR(50), CONSTRAINT PK_dengue PRIMARY KEY (Date,country) ); # de date naar de table verplaatsen COPY dengue_data FROM &#39;C:/Users/Bas/Desktop/School/Programmeren/datascience/portfolio/data/dengue_data_tidy.csv&#39; WITH (FORMAT csv); # de table laten zien SELECT * FROM dengue_data; Here I connect to the SQL database and inspect the database with the help of R. # connect to the database con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;kaas&quot;) # laat de tables zien dbListTables(con) ## [1] &quot;flu_data&quot; &quot;dengue_data&quot; &quot;gapminder&quot; # laat de colummen in flu_data zien dbListFields(con, &quot;flu_data&quot;) ## [1] &quot;date&quot; &quot;country&quot; &quot;cases&quot; # laat het tabel flu_data zien head(dbGetQuery(con, &#39;SELECT * FROM flu_data&#39;)) ## date country cases ## 1 Date country cases ## 2 2002-12-29 Argentina NA ## 3 2002-12-29 Australia NA ## 4 2002-12-29 Austria NA ## 5 2002-12-29 Belgium NA ## 6 2002-12-29 Bolivia NA # disconnect van de database dbDisconnect(con) These are the commands I used in the sql database with the program DBeaver to create the gapminder table. #create gapminder table CREATE TABLE gapminder ( country VARCHAR(50), Date VARCHAR(50), infant_mortality VARCHAR(50) not null, life_expectancy VARCHAR(50) not null, fertitlity VARCHAR(50) not null, population VARCHAR(50) not null, gdp VARCHAR(50) not null, continent VARCHAR(50), region VARCHAR(50), CONSTRAINT PK_gapminder PRIMARY KEY (Date,country) ); #import the gampinder file COPY gapminder FROM &#39;C:/Users/Bas/Desktop/School/Programmeren/datascience/portfolio/data/gapminder_tidy.csv&#39; WITH (FORMAT csv); # laat de tabel zien SELECT * FROM gapminder; Here I select two table together forming 1 table wich I save as “gapminder_flu” # connect to the database con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;kaas&quot;) gapminder_flu &lt;- dbGetQuery(con, &#39;select distinct * from flu_data,gapminder where flu_data.country = gapminder.country;&#39; ) # disconnect van de database dbDisconnect(con) Now I have the data wrangled an can make all kinds of graphs with the data # filter for the Netherlands and calculate the average cases over time cases_netherlands &lt;- gapminder_flu %&gt;% filter(country == &quot;Netherlands&quot;) %&gt;% group_by(date=as.Date(date)) %&gt;% summarise(mean_cases=mean(as.numeric(cases))) # make a gg line plot netherlands_graph &lt;- cases_netherlands %&gt;% ggplot(aes(x = date, y = mean_cases)) + geom_line() + labs( title = &quot;flu cases over time in the netherlands&quot;, y = &quot;cases&quot; ) ggplotly(netherlands_graph) # string naar date veranderen gapminder_flu$date &lt;- as.Date(gapminder_flu$date) # nieuw object maken waar het gemmidelde cases is berekend in 2015 in europa country_cases &lt;- gapminder_flu %&gt;% filter(between(date, as.Date(&quot;2015-01-01&quot;), as.Date(&quot;2015-12-30&quot;))) %&gt;% filter(continent == &quot;Europe&quot;) %&gt;% group_by(country) %&gt;% summarise(mean_cases=mean(as.numeric(cases))) # ggplot maken graph &lt;-country_cases %&gt;% ggplot(aes(x = country, y = mean_cases, fill = country_cases$country)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ labs( title = &quot;Average flu cases per europian country in 2015&quot; ) # ggplot in een plotly veranderen ggplotly(graph) # string naar date veranderen gapminder_flu$date &lt;- as.Date(gapminder_flu$date) # nieuw object maken waar het gemmidelde life_expectancy is berekend in 2015 in europa country_life &lt;- gapminder_flu %&gt;% filter(between(date, as.Date(&quot;2015-01-01&quot;), as.Date(&quot;2015-12-30&quot;))) %&gt;% filter(continent == &quot;Europe&quot;) %&gt;% group_by(country) %&gt;% summarise(mean_cases=mean(as.numeric(life_expectancy))) # ggplot maken graph_life &lt;-country_life %&gt;% ggplot(aes(x = country, y = mean_cases, fill = country_cases$country)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ labs( title = &quot;Average life expectancy per europian country in 2015&quot; ) # ggplot in een plotly veranderen ggplotly(graph_life) "],["package-creation.html", "8 Package creation 8.1 description 8.2 installation", " 8 Package creation 8.1 description For a school project wich I am working on I have made a package called graphify. With the help of this package it is possible to create muliple graphs using a few function wich are included in the package 8.2 installation To visit the github page of the package you can click here You can also install the package using the following code: # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;bburg2/graphify&quot;, build_vignettes = TRUE) "],["working-with-parameters.html", "9 Working with parameters", " 9 Working with parameters One of the things that I have learned is to work with parameters in markdown files. With the help of parameters its easy to change what you are analysing. The goal of parameters is to make it readable for people but also readable for the program. For the purpose of showing my skills with markdown parameters I made an analysis based on covid-19 data. With this markdown file it is possible to change parameters. The parameters that are possible to change are: Country from which you want to see the data year in which you want to look firstmonth and lastmonth, so you can look at data between specific months continent from which you want to look at In the video beneath you can look at the easy way to change parameters Working with parameters library(readr) library(here) library(tidyverse) # loading the data to an object covid_data &lt;- read_csv(here(&quot;data&quot;, &quot;covid_data.csv&quot;)) # change the date collumn to a date class covid_data$dateRep &lt;- as.Date(covid_data$dateRep, tryFormats = c(&quot;%d/%m/%y&quot;)) # filter by country, year an month country_filter &lt;- covid_data %&gt;% filter(countriesAndTerritories == params$country &amp; year == params$year &amp; month %in% (params$firstmonth:params$lastmonth)) # make a line graph based on the filter output country_filter %&gt;% ggplot(aes(x = dateRep, y = cases)) + geom_line() + labs( title = paste(&quot;Covid cases from&quot;,params$country, &quot;in&quot;, params$year), x = &quot;Date&quot; ) # filter by year and continent and sum the amount of deaths per country country_deaths &lt;- covid_data %&gt;% group_by(countriesAndTerritories) %&gt;% filter(year == params$year, continentExp == params$continent) %&gt;% summarize(deaths = sum(deaths, na.rm = TRUE)) # make a bar graph based on the filter output country_deaths %&gt;% ggplot(aes(x = countriesAndTerritories, y = deaths)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ labs( title = paste(&quot;covid related deaths per country in&quot;, params$continent, &quot;in&quot;, params$year), x = &quot;countries&quot; ) "]]
